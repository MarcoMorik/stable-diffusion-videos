{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/nateraw/stable-diffusion-videos/blob/main/stable_diffusion_videos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Stable Diffusion Videos\n",
    "\n",
    "This notebook allows you to generate videos by interpolating the latent space of [Stable Diffusion](https://github.com/CompVis/stable-diffusion).\n",
    "\n",
    "You can either dream up different versions of the same prompt, or morph between different text prompts (with seeds set for each for reproducibility).\n",
    "\n",
    "If you like this notebook:\n",
    "- consider giving the [repo a star](https://github.com/nateraw/stable-diffusion-videos) ‚≠êÔ∏è\n",
    "- consider following me on Github [@nateraw](https://github.com/nateraw) \n",
    "\n",
    "You can file any issues/feature requests [here](https://github.com/nateraw/stable-diffusion-videos/issues)\n",
    "\n",
    "Enjoy ü§ó"
   ],
   "metadata": {
    "id": "z4GhhH25OdYq"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup"
   ],
   "metadata": {
    "id": "dvdCBpWWOhW-"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xwfc0ej1L9A0"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "! pip install stable_diffusion_videos[realesrgan]\n",
    "! git config --global credential.helper store"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Authenticate with Hugging Face Hub\n",
    "\n",
    "You have to be a registered user in ü§ó Hugging Face Hub, and you'll also need to use an access token for the code to work. For more information on access tokens, please refer to [this section of the documentation](https://huggingface.co/docs/hub/security-tokens)."
   ],
   "metadata": {
    "id": "dR5iVGYbOky5"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ],
   "metadata": {
    "id": "GmejIGhFMTXG"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run the App üöÄ"
   ],
   "metadata": {
    "id": "H7UOKJhVOonb"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load the Interface\n",
    "\n",
    "This step will take a couple minutes the first time you run it."
   ],
   "metadata": {
    "id": "g71hslP8OntM"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from stable_diffusion_videos import interface"
   ],
   "metadata": {
    "id": "bgSNS368L-DV"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#@title Connect to Google Drive to Save Outputs\n",
    "\n",
    "#@markdown If you want to connect Google Drive, click the checkbox below and run this cell. You'll be prompted to authenticate.\n",
    "\n",
    "#@markdown If you just want to save your outputs in this Colab session, don't worry about this cell\n",
    "\n",
    "connect_google_drive = True #@param {type:\"boolean\"}\n",
    "\n",
    "#@markdown Then, in the interface, use this path as the `output` in the Video tab to save your videos to Google Drive:\n",
    "\n",
    "#@markdown > /content/gdrive/MyDrive/stable_diffusion_videos\n",
    "\n",
    "\n",
    "if connect_google_drive:\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount('/content/gdrive')"
   ],
   "metadata": {
    "id": "kidtsR3c2P9Z",
    "cellView": "form"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Launch\n",
    "\n",
    "This cell launches a Gradio Interface. Here's how I suggest you use it:\n",
    "\n",
    "1. Use the \"Images\" tab to generate images you like.\n",
    "    - Find two images you want to morph between\n",
    "    - These images should use the same settings (guidance scale, height, width)\n",
    "    - Keep track of the seeds/settings you used so you can reproduce them\n",
    "\n",
    "2. Generate videos using the \"Videos\" tab\n",
    "    - Using the images you found from the step above, provide the prompts/seeds you recorded\n",
    "    - Set the `num_walk_steps` - for testing you can use a small number like 3 or 5, but to get great results you'll want to use something larger (60-200 steps). \n",
    "\n",
    "üí° **Pro tip** - Click the link that looks like `https://<id-number>.gradio.app` below , and you'll be able to view it in full screen."
   ],
   "metadata": {
    "id": "VxjRVNnMOtgU"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "interface.launch(debug=True)"
   ],
   "metadata": {
    "id": "8es3_onUOL3J"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {
    "id": "mFCoTvlnPi4u"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Use `walk` programatically\n",
    "\n",
    "The other option is to not use the interface, and instead use `walk` programatically. Here's how you would do that..."
   ],
   "metadata": {
    "id": "SjTQLCiLOWeo"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First we define a helper fn for visualizing videos in colab"
   ],
   "metadata": {
    "id": "fGQPClGwOR9R"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "def visualize_video_colab(video_path):\n",
    "    mp4 = open(video_path,'rb').read()\n",
    "    data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "    return HTML(\"\"\"\n",
    "    <video width=400 controls>\n",
    "        <source src=\"%s\" type=\"video/mp4\">\n",
    "    </video>\n",
    "    \"\"\" % data_url)"
   ],
   "metadata": {
    "id": "GqTWc8ZhNeLU"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Walk! üö∂‚Äç‚ôÄÔ∏è"
   ],
   "metadata": {
    "id": "Vd_RzwkoPM7X"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from stable_diffusion_videos import walk\n",
    "\n",
    "text = [\"A realistic painting of a owl flying through a colorful landscape.\",\n",
    "        \"A beautiful painting of an owl flying towards a forest.\",\n",
    "        \"A painting of an owl finding a pill in the forest.\",\n",
    "        \"A artistic cartoon of a owl swallow a pill in the forest.\",\n",
    "        \"A colorful trippy painting of a owl in a forest.\",\n",
    "        \"A trippy illustration of a owl. The Bottom is Colorful, while the top is black and white.\",\n",
    "        \"A painting of a spooky horrible forest. In the middle is a bleeding owl. The eyes are scary.\",\n",
    "        \"A horrifying cartoon of a dying owl, stabbed by a knife.\",\n",
    "        \"A sad funeral of birds grieve for the dead owl.\",  # 97 ?\n",
    "        \"A horrfying painting of a oak tree growing over the grave.\",  # 97\n",
    "        \"The owl is flying towards hell, burning to ashes, abstract horrifying art\",\n",
    "        \"A trippy sign of The End\", ]\n",
    "seed = [15, 13, 13, 7532, 2001, 1993, 21534, 2234, 97, 97, 97, 2001]\n",
    "\n",
    "video_path = walk(text, seed, num_steps=20, name=\"OwlFinal\", make_video=True,\n",
    "                  latent_interpolation_steps=15, do_loop=True)\n",
    "visualize_video_colab(video_path)"
   ],
   "metadata": {
    "id": "Hv2wBZXXMQ-I"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
